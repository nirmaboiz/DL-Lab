{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daaaa707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score\n",
    "\n",
    "RANDOM_SEED = 2021\n",
    "TEST_PCT = 0.3\n",
    "LABELS = [\"Normal\",\"Fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e45c8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c85c9ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any nulls in the dataset False\n",
      "-------\n",
      "No. of unique labels 2\n",
      "Label values [0 1]\n",
      "-------\n",
      "Break down of Normal and Fraud Transcations\n",
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for any null values\n",
    "print(\"Any nulls in the dataset\",dataset.isnull().values.any())\n",
    "print('-------')\n",
    "print(\"No. of unique labels\",len(dataset['Class'].unique()))\n",
    "print(\"Label values\",dataset.Class.unique())\n",
    "\n",
    "#0 is for normal credit card transcation\n",
    "#1 is for fraudulent credit card transcation\n",
    "print('-------')\n",
    "print(\"Break down of Normal and Fraud Transcations\")\n",
    "print(pd.value_counts(dataset['Class'],sort=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86b3c7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of Observations')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualizing the imbalanced dataset\n",
    "count_classes = pd.value_counts(dataset['Class'],sort=True)\n",
    "count_classes.plot(kind='bar',rot=0)\n",
    "plt.xticks(range(len(dataset['Class'].unique())),dataset.Class.unique())\n",
    "plt.title(\"Frequency by observation number\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c70b080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Save the normal and fradulent transcations in seperate dataframe\n",
    "normal_dataset = dataset[dataset.Class == 0]\n",
    "fraud_dataset = dataset[dataset.Class == 1]\n",
    "\n",
    "#Visualize transcation amounts for normal and fraudulent transcations\n",
    "bins = np.linspace(200,2500,100)\n",
    "plt.hist(normal_dataset.Amount,bins=bins,alpha=1,density=True,label='Normal')\n",
    "plt.hist(fraud_dataset.Amount,bins=bins,alpha=0.5,density=True,label='Fraud')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Transcation Amount vs Percentage of Transcations\")\n",
    "plt.xlabel(\"Transcation Amount (USD)\")\n",
    "plt.ylabel(\"Percentage of Transcations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "818efce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c06ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "dataset['Time'] = sc.fit_transform(dataset['Time'].values.reshape(-1,1))\n",
    "dataset['Amount'] = sc.fit_transform(dataset['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3252120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = dataset.values\n",
    "#The last element contains if the transcation is normal which is represented by 0 and if fraud then 1\n",
    "labels = raw_data[:,-1]\n",
    "\n",
    "#The other data points are the electrocadriogram data\n",
    "data = raw_data[:,0:-1]\n",
    "\n",
    "train_data,test_data,train_labels,test_labels = train_test_split(data,labels,test_size = 0.2,random_state =2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eb77382",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = tf.reduce_min(train_data)\n",
    "max_val = tf.reduce_max(train_data)\n",
    "\n",
    "train_data = (train_data - min_val) / (max_val - min_val)\n",
    "test_data = (test_data - min_val) / (max_val - min_val)\n",
    "\n",
    "train_data = tf.cast(train_data,tf.float32)\n",
    "test_data = tf.cast(test_data,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccef8723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of records in Fraud Train Data= 389\n",
      "No. of records in Normal Train Data= 227456\n",
      "No. of records in Fraud Test Data= 103\n",
      "No. of records in Normal Test Data= 56859\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_labels.astype(bool)\n",
    "test_labels = test_labels.astype(bool)\n",
    "\n",
    "#Creating normal and fraud datasets\n",
    "normal_train_data = train_data[~train_labels]\n",
    "normal_test_data = test_data[~test_labels]\n",
    "\n",
    "fraud_train_data = train_data[train_labels]\n",
    "fraud_test_data = test_data[test_labels]\n",
    "print(\"No. of records in Fraud Train Data=\",len(fraud_train_data))\n",
    "print(\"No. of records in Normal Train Data=\",len(normal_train_data))\n",
    "print(\"No. of records in Fraud Test Data=\",len(fraud_test_data))\n",
    "print(\"No. of records in Normal Test Data=\",len(normal_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86884b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 50\n",
    "batch_size = 64\n",
    "input_dim = normal_train_data.shape[1]\n",
    "#num of columns,30\n",
    "encoding_dim = 14\n",
    "hidden_dim1 = int(encoding_dim / 2)\n",
    "hidden_dim2 = 4\n",
    "learning_rate = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47ba4bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 30)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 14)                434       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 105       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 32        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 35        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7)                 0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 14)                112       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 30)                450       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,168\n",
      "Trainable params: 1,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#input layer\n",
    "input_layer = tf.keras.layers.Input(shape=(input_dim,))\n",
    "\n",
    "#Encoder\n",
    "encoder = tf.keras.layers.Dense(encoding_dim,activation=\"tanh\",activity_regularizer = tf.keras.regularizers.l2(learning_rate))(input_layer)\n",
    "encoder = tf.keras.layers.Dropout(0.2)(encoder)\n",
    "encoder = tf.keras.layers.Dense(hidden_dim1,activation='relu')(encoder)\n",
    "encoder = tf.keras.layers.Dense(hidden_dim2,activation=tf.nn.leaky_relu)(encoder)\n",
    "\n",
    "#Decoder\n",
    "decoder = tf.keras.layers.Dense(hidden_dim1,activation='relu')(encoder)\n",
    "decoder = tf.keras.layers.Dropout(0.2)(decoder)\n",
    "decoder = tf.keras.layers.Dense(encoding_dim,activation='relu')(decoder)\n",
    "decoder = tf.keras.layers.Dense(input_dim,activation='tanh')(decoder)\n",
    "\n",
    "#Autoencoder\n",
    "autoencoder = tf.keras.Model(inputs = input_layer,outputs = decoder)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33a84297",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = tf.keras.callbacks.ModelCheckpoint(filepath=\"autoencoder_fraud.h5\",mode='min',monitor='val_loss',verbose=2,save_best_only=True)\n",
    "#Define our early stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.0001,\n",
    "                patience=10,\n",
    "                verbose=11,\n",
    "                mode='min',\n",
    "                restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ced15a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(metrics=['accuracy'],loss= 'mean_squared_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e0a740e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3548/3554 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.0387\n",
      "Epoch 1: val_loss improved from inf to 0.00002, saving model to autoencoder_fraud.h5\n",
      "3554/3554 [==============================] - 24s 6ms/step - loss: 0.0046 - accuracy: 0.0387 - val_loss: 2.3670e-05 - val_accuracy: 6.1444e-04\n",
      "Epoch 2/50\n",
      "3550/3554 [============================>.] - ETA: 0s - loss: 1.9316e-05 - accuracy: 0.0580\n",
      "Epoch 2: val_loss improved from 0.00002 to 0.00002, saving model to autoencoder_fraud.h5\n",
      "3554/3554 [==============================] - 22s 6ms/step - loss: 1.9313e-05 - accuracy: 0.0580 - val_loss: 2.3640e-05 - val_accuracy: 6.1444e-04\n",
      "Epoch 3/50\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 1.9480e-05 - accuracy: 0.0622\n",
      "Epoch 3: val_loss improved from 0.00002 to 0.00002, saving model to autoencoder_fraud.h5\n",
      "3554/3554 [==============================] - 24s 7ms/step - loss: 1.9480e-05 - accuracy: 0.0622 - val_loss: 2.1333e-05 - val_accuracy: 0.0134\n",
      "Epoch 4/50\n",
      "3553/3554 [============================>.] - ETA: 0s - loss: 1.9472e-05 - accuracy: 0.0561\n",
      "Epoch 4: val_loss improved from 0.00002 to 0.00002, saving model to autoencoder_fraud.h5\n",
      "3554/3554 [==============================] - 27s 8ms/step - loss: 1.9471e-05 - accuracy: 0.0561 - val_loss: 1.9836e-05 - val_accuracy: 0.0452\n",
      "Epoch 5/50\n",
      "3548/3554 [============================>.] - ETA: 0s - loss: 1.9559e-05 - accuracy: 0.0631\n",
      "Epoch 5: val_loss did not improve from 0.00002\n",
      "3554/3554 [==============================] - 24s 7ms/step - loss: 1.9568e-05 - accuracy: 0.0631 - val_loss: 2.0637e-05 - val_accuracy: 0.0189\n",
      "Epoch 6/50\n",
      "3550/3554 [============================>.] - ETA: 0s - loss: 1.9535e-05 - accuracy: 0.0617\n",
      "Epoch 6: val_loss did not improve from 0.00002\n",
      "3554/3554 [==============================] - 26s 7ms/step - loss: 1.9533e-05 - accuracy: 0.0617 - val_loss: 2.0177e-05 - val_accuracy: 0.1279\n",
      "Epoch 7/50\n",
      "3492/3554 [============================>.] - ETA: 0s - loss: 1.9488e-05 - accuracy: 0.0608"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8724/2200823555.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = autoencoder.fit(normal_train_data,normal_train_data,epochs = nb_epoch,\n\u001b[0m\u001b[0;32m      2\u001b[0m                          \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                          \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                          \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                          callbacks = [cp,early_stop]).history\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1570\u001b[1;33m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1571\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    468\u001b[0m         \"\"\"\n\u001b[0;32m    469\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             raise ValueError(\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1157\u001b[0m             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, current, values, finalize)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[0mio_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_break\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\io_utils.py\u001b[0m in \u001b[0;36mprint_msg\u001b[1;34m(message, line_break)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    454\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m                 \u001b[1;31m# and give a timeout to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m                     \u001b[1;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m                     \u001b[1;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(normal_train_data,normal_train_data,epochs = nb_epoch,\n",
    "                         batch_size = batch_size,shuffle = True,\n",
    "                         validation_data = (test_data,test_data),\n",
    "                         verbose=1,\n",
    "                         callbacks = [cp,early_stop]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28874afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'],linewidth = 2,label = 'Train')\n",
    "plt.plot(history['val_loss'],linewidth = 2,label = 'Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "#plt.ylim(ymin=0.70,ymax=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa4e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_predictions = autoencoder.predict(test_data)\n",
    "mse = np.mean(np.power(test_data - test_x_predictions, 2),axis = 1)\n",
    "error_df = pd.DataFrame({'Reconstruction_error':mse,\n",
    "                         'True_class':test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27761c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_fixed = 50\n",
    "groups = error_df.groupby('True_class')\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "for name,group in groups:\n",
    "        ax.plot(group.index,group.Reconstruction_error,marker='o',ms = 3.5,linestyle='',\n",
    "                label = \"Fraud\" if  name==1 else \"Normal\")\n",
    "ax.hlines(threshold_fixed,ax.get_xlim()[0],ax.get_xlim()[1],colors=\"r\",zorder=100,label=\"Threshold\")\n",
    "ax.legend()\n",
    "plt.title(\"Reconstructions error for normal and fraud data\")\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Data point index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e8cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_fixed = 52\n",
    "pred_y = [1 if e > threshold_fixed else 0 \n",
    "          for e in \n",
    "        error_df.Reconstruction_error.values]\n",
    "error_df['pred'] = pred_y\n",
    "conf_matrix = confusion_matrix(error_df.True_class,pred_y)\n",
    "\n",
    "plt.figure(figsize = (4,4))\n",
    "sns.heatmap(conf_matrix,xticklabels = LABELS,yticklabels = LABELS,annot = True,fmt=\"d\")\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel(\"True class\")\n",
    "plt.xlabel(\"Predicted class\")\n",
    "plt.show()\n",
    "\n",
    "#Print Accuracy,Precision and Recall\n",
    "print(\"Accuracy :\",accuracy_score(error_df['True_class'],error_df['pred']))\n",
    "print(\"Recall :\",recall_score(error_df['True_class'],error_df['pred']))\n",
    "print(\"Precision :\",precision_score(error_df['True_class'],error_df['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283036e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f38c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
